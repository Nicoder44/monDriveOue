<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>M&eacute;mo sur les Arbres de D&eacute;cision et la Classification Supervis&eacute;e</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        
    </head>
    <body class="vscode-body vscode-light">
        <h1 id="mémo-sur-les-arbres-de-décision-et-la-classification-supervisée">Mémo sur les Arbres de Décision et la Classification Supervisée</h1>
<h2 id="1-arbres-de-décision">1. Arbres de Décision</h2>
<ul>
<li>
<p><strong>Définition :</strong> Un arbre de décision est un modèle de classification basé sur des critères qui divise l'espace des données en sous-régions homogènes.</p>
</li>
<li>
<p><strong>Construction :</strong> L'arbre est construit en choisissant des critères de manière itérative pour diviser les nœuds jusqu'à l'obtention de feuilles pures.</p>
</li>
<li>
<p><strong>Pureté d'un Nœud :</strong> Mesurée par l'indice de Gini, qui évalue l'homogénéité du nœud en termes de classes.</p>
</li>
<li>
<p><strong>Surapprentissage :</strong> Risque d'ajustement excessif à un ensemble de données d'entraînement, évité en limitant la profondeur de l'arbre.</p>
</li>
</ul>
<h2 id="2-indice-de-gini">2. Indice de Gini</h2>
<p>L'indice de Gini pour un nœud est calculé par la formule :</p>
<p>[ G(t) = 1 - \sum_{j} p(j|t)^2 ]</p>
<p>où ( p(j|t) ) est la proportion d'observations de la classe ( j ) au nœud ( t ).</p>
<h2 id="3-exemple-pratique">3. Exemple Pratique</h2>
<ul>
<li>
<p><strong>Construction :</strong> L'arbre est construit en choisissant des paramètres (X, seuil) pour minimiser l'indice de Gini.</p>
</li>
<li>
<p><strong>Interprétation :</strong> Un nœud avec un indice de Gini proche de 0 est pur, tandis qu'un indice proche de 1 indique une impureté élevée.</p>
</li>
</ul>
<h2 id="4-application-avec-scikit-learn">4. Application avec scikit-learn</h2>
<ul>
<li>
<p><strong>Utilisation :</strong> La classe <code>DecisionTreeClassifier</code> de scikit-learn permet de créer et d'entraîner des arbres de décision.</p>
</li>
<li>
<p><strong>Évaluation :</strong> L'évaluation de la performance se fait en divisant les données en ensembles d'entraînement et de test.</p>
</li>
<li>
<p><strong>Visualisation :</strong> La représentation graphique de l'arbre peut être obtenue avec la librairie graphviz.</p>
</li>
</ul>
<h2 id="5-gestion-du-surapprentissage">5. Gestion du Surapprentissage</h2>
<ul>
<li><strong>Profondeur de l'Arbre :</strong> Limiter la profondeur de l'arbre aide à prévenir le surapprentissage en évitant une trop grande complexité.</li>
</ul>
<hr>
<p><strong>Remarque :</strong> Adapter les paramètres, choisir judicieusement les critères, et gérer le surapprentissage sont des éléments clés pour un arbre de décision efficace.</p>

        
        
    </body>
    </html>